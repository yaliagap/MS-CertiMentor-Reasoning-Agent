# ğŸ“ MS-CertiMentor

> **Multi-Agent Reasoning System for Microsoft Certification Preparation**

A sophisticated multi-agent system that helps students prepare for Microsoft certification exams through intelligent learning path curation, personalized study planning, automated engagement, and readiness assessment.

Built for **AgentsLeague Battle #2 - Reasoning Agents** with Microsoft Foundry.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Agent Framework](https://img.shields.io/badge/Framework-Microsoft%20Agent-green.svg)](https://github.com/microsoft/agent-framework)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸŒŸ Features

### Core Capabilities

âœ… **Intelligent Learning Path Curation**
- Real-time integration with Microsoft Learn via MCP (Model Context Protocol)
- **Level-aware content selection** (beginner, intermediate, advanced)
- Priority domain identification with exam weight analysis
- Relevance scoring (1-10) for each learning path
- Module-level breakdown with importance rationale

âœ… **Personalized Study Planning**
- **Customized based on student availability** (days per week, hours per day)
- Week-by-week structured schedules aligned with student capacity
- Daily session breakdown with specific objectives
- 4 milestone system (25%, 50%, 75%, 100%) with validation methods
- Rest days and buffer time automatically incorporated
- Realistic timelines that match student commitment

âœ… **Automated Engagement & Accountability**
- **Adaptive tone** based on student experience level
- Scheduled study reminders with direct resource URLs
- Motivational messaging tailored to progress
- Progress tracking with milestone celebrations

âœ… **Readiness Assessment (Quiz Generation)**
- 10-question certification-style quiz generated by Assessment Agent
- Difficulty distribution: 30% Easy, 50% Medium, 20% Hard
- Bloom's Taxonomy alignment (Remember, Understand, Apply, Analyze, Evaluate, Create)
- Scenario-based questions for practical skill evaluation
- Questions mapped to exam domains with detailed explanations
- Interactive quiz interface with answer collection

âœ… **Educational Feedback & Learning (NEW)**
- **Question-by-question feedback** by Assessment Evaluator Agent
- **Detailed explanations** for both correct and incorrect answers
- **"Why correct is right"** explanations (2-4 sentences per question)
- **"Why wrong is wrong"** explanations for mistakes (2-3 sentences)
- **Specific study tips** for each incorrect answer
- **Key concept identification** - highlights what each question tests
- **Domain performance analysis** - groups results by certification domain
- **Strengths & weaknesses** - clear identification of strong/weak areas
- **Encouraging tone** - constructive feedback that motivates learning
- **Actionable next steps** - prioritized focus areas based on mistakes

âœ… **Strategic Exam Readiness Evaluation**
- **AI-powered strategic assessment by Exam Plan Agent** - holistic readiness evaluation
- **Automatic score calculation** - overall score and per-domain breakdown
- **Domain-level performance analysis** - maps questions to exam domains with weights
- **3-tier decision logic** (ready â‰¥80%, nearly_ready 65-79%, not_ready <65%)
- **Critical risk detection** - identifies high-weight domains (>20%) scoring <60%
- **Intelligent preparation timeline** - calculates days needed based on weak domains
- **Personalized recommendations** - targeted next steps prioritized by weakness
- **Adaptive feedback** - constructive guidance regardless of score (no "game over")
- Certification recommendation with registration URLs
- Exam strategy and day-of tips tailored to performance

---

## ğŸ—ï¸ Architecture

### Multi-Agent System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PREPARATION PHASE                            â”‚
â”‚              (Sequential Workflow - 3 Agents)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1. Learning Path Curator               â”‚
        â”‚     â€¢ Searches Microsoft Learn (MCP)    â”‚
        â”‚     â€¢ Adapts to student level           â”‚
        â”‚     â€¢ Prioritizes domains by weight     â”‚
        â”‚     â€¢ Output: CuratedLearningPlan       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  2. Study Plan Generator                â”‚
        â”‚     â€¢ Considers study availability      â”‚
        â”‚     â€¢ Creates weekly schedule           â”‚
        â”‚     â€¢ Defines daily sessions with URLs  â”‚
        â”‚     â€¢ Output: StudyPlan                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  3. Engagement Agent                    â”‚
        â”‚     â€¢ Schedules reminders with links    â”‚
        â”‚     â€¢ Adaptive motivational tone        â”‚
        â”‚     â€¢ Output: EngagementPlan            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HUMAN-IN-THE-LOOP CHECKPOINT                       â”‚
â”‚           Student confirms readiness for assessment             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  4. Assessment Agent                    â”‚
        â”‚     â€¢ Generates domain-mapped quiz      â”‚
        â”‚     â€¢ Collects student answers          â”‚
        â”‚     â€¢ Output: Quiz + User Answers       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  5. Assessment Evaluator (NEW)          â”‚
        â”‚     â€¢ Reviews each question/answer      â”‚
        â”‚     â€¢ Explains correct/incorrect        â”‚
        â”‚     â€¢ Identifies learning gaps          â”‚
        â”‚     â€¢ Provides study tips               â”‚
        â”‚     â€¢ Output: AssessmentFeedback        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6. Exam Plan Agent (Strategic)         â”‚
        â”‚     â€¢ Evaluates overall readiness       â”‚
        â”‚     â€¢ Calculates domain scores          â”‚
        â”‚     â€¢ Applies decision logic            â”‚
        â”‚     â€¢ Recommends certification action   â”‚
        â”‚     â€¢ Output: ExamPlan with timeline    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
              Strategic Recommendation:
         Ready (â‰¥80%) | Nearly Ready (65-79%) | Not Ready (<65%)
              â†“                 â†“                      â†“
         Book Exam      Reinforce Weak Areas    Rebuild Foundation
```

### Technology Stack

- **Framework**: [Microsoft Agent Framework](https://github.com/microsoft/agent-framework) (Python)
- **LLM Provider**: Azure OpenAI Service
- **Orchestration**: Sequential Workflows with `SequentialBuilder`
- **Model**: GPT-4o (configurable)
- **Agent Client**: `AzureOpenAIChatClient`
- **MCP Integration**: Microsoft Learn MCP Server
- **Data Validation**: Pydantic v2
- **Language**: Python 3.11+

### Agent Configuration

| Agent | Temperature | Role | Responsibilities |
|-------|-------------|------|------------------|
| **Learning Path Curator** | 0.3 | Content Discovery | Search Microsoft Learn paths adapted to student level |
| **Study Plan Generator** | 0.4 | Planning | Create realistic timelines based on student availability |
| **Engagement Agent** | 0.6 | Motivation | Generate level-appropriate reminders with resource links |
| **Assessment Agent** | 0.2 | Quiz Generation | Generate 10 contextual questions with proper difficulty distribution |
| **Assessment Evaluator** | 0.3 | Educational Feedback | Review answers, explain correct/incorrect, provide study tips |
| **Exam Plan Agent** | 0.3 | Strategic Advisor | Evaluate readiness, calculate scores, recommend certification actions |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Azure OpenAI Service resource with GPT-4o deployment
- Azure OpenAI API key and endpoint

### Installation

```bash
# Clone repository
git clone <repository-url>
cd MS-CertiMentor-Reasoning-Agent

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your Azure OpenAI credentials
```

### Configuration

Edit `.env` with your Azure OpenAI credentials:

```bash
# Azure OpenAI Service Configuration
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_VERSION=2025-01-01-preview

# Environment
ENVIRONMENT=development
```

**Get your credentials from Azure Portal:**
1. Go to your Azure OpenAI resource
2. Navigate to "Keys and Endpoint"
3. Copy KEY 1 â†’ `AZURE_OPENAI_API_KEY`
4. Copy Endpoint â†’ `AZURE_OPENAI_ENDPOINT`
5. Go to "Model deployments" â†’ Copy deployment name â†’ `AZURE_OPENAI_DEPLOYMENT_NAME`

### Verify Connection

```bash
python test_azure_connection.py
```

Expected output:
```
[OK] Connection successful!
[OK] Model response: Hello
```

---

## ğŸ® Running the System

### Main Execution

```bash
python main.py
```

This runs the complete multi-agent workflow with:
- âœ… Azure OpenAI Service integration
- âœ… Sequential Workflow orchestration
- âœ… All 6 specialized agents
- âœ… Interactive quiz with detailed feedback
- âœ… Human-in-the-loop checkpoints

---

## ğŸ“Š Example Execution

```bash
$ python main.py

======================================================================
[MS-CertiMentor] Multi-Agent System with Azure OpenAI
======================================================================

[MODE] Azure OpenAI Service + Sequential Workflows
[ENDPOINT] https://your-resource.openai.azure.com/
[MODEL] gpt-4o

What Microsoft certification topics are you interested in?
> Azure AI Fundamentals

Your email for reminders?
> student@example.com

What is your experience level? (beginner/intermediate/advanced)
> beginner

How many days per week can you study? (1-7)
> 5

How many hours per day can you dedicate? (0.5-8.0)
> 2.0

[CONFIGURATION]
âœ“ Topics: Azure AI Fundamentals
âœ“ Level: beginner
âœ“ Study schedule: 5 days/week, 2.0 hours/day
âœ“ Total weekly hours: 10.0 hours/week

======================================================================
PHASE 1: PREPARATION SUBWORKFLOW (Sequential)
======================================================================

[AGENT: LEARNING_PATH_CURATOR]
âœ“ 3 Microsoft Learn paths curated (beginner-friendly)
  - Azure AI Fundamentals: AI Overview (8h, difficulty: beginner)
  - Get started with AI on Azure (6h, difficulty: beginner)
  - Explore Azure AI Services (5h, difficulty: beginner)
âœ“ 4 priority domains identified
âœ“ Relevance scores: 10/10, 9/10, 9/10

[AGENT: STUDY_PLAN_GENERATOR]
âœ“ 6-week study plan created (adapted to 5 days/week Ã— 2h/day)
  - 30 total sessions (10h/week = 60 hours total)
  - Daily sessions matched to availability
  - 4 milestones: Week 2 (25%), Week 3 (50%), Week 5 (75%), Week 6 (100%)
  - Rest days: Weekends

[AGENT: ENGAGEMENT_AGENT]
âœ“ 33 reminders scheduled
  - 9 session reminders (with module URLs)
  - 18 buffer reminders (catch-up/review)
  - 3 milestone reminders
  - 3 assessment reminders
âœ“ Motivational strategy: Beginner-supportive with confidence building

======================================================================
PHASE 2: HUMAN-IN-THE-LOOP CHECKPOINT
======================================================================

[CHECKPOINT] Are you ready for the assessment?
> yes

======================================================================
PHASE 3: ASSESSMENT (Quiz Generation)
======================================================================

[AGENT: ASSESSMENT_AGENT]
âœ“ 10 questions generated
âœ“ Distribution: 3 easy, 5 medium, 2 hard
âœ“ 3 scenario-based questions

[INTERACTIVE QUIZ]
Question 1 [MEDIUM]: Which Azure service is used for ML workloads?
A) Azure Storage
B) Azure Machine Learning
C) Azure Functions
D) Azure SQL Database

Your answer (A/B/C/D): B
âœ“ Answer recorded

Question 2 [EASY]: What does AI stand for?
Your answer (A/B/C/D): A
âœ“ Answer recorded

...

[ASSESSMENT COMPLETED]
âœ“ All 10 answers recorded

Your responses will now be evaluated...

======================================================================
PHASE 3B: ASSESSMENT EVALUATION & FEEDBACK
======================================================================

[AGENT: ASSESSMENT_EVALUATOR]
Reviewing your answers and providing detailed feedback...

ğŸ“Š ASSESSMENT EVALUATION RESULTS
======================================================================

ğŸ“ˆ OVERALL PERFORMANCE:
  Score: 8/10 (80.0%)
  Status: âœ… PASSED
  Threshold: 70% (7/10 questions)

ğŸ“š PERFORMANCE BY DOMAIN:

  ğŸŸ¢ Azure AI Services
     Score: 3/3 (100.0%)
     Status: STRONG

  ğŸŸ¡ Machine Learning on Azure
     Score: 3/4 (75.0%)
     Status: STRONG

  ğŸŸ¡ Natural Language Processing
     Score: 2/3 (66.7%)
     Status: ADEQUATE

ğŸ’ª STRENGTHS:
  âœ“ Azure AI Services (100% - excellent understanding)
  âœ“ Machine Learning fundamentals (75% - solid grasp)

âš ï¸ AREAS FOR IMPROVEMENT:
  â€¢ Natural Language Processing (66.7% - needs review of NLP services)

======================================================================
ğŸ“ DETAILED QUESTION FEEDBACK
======================================================================

âœ… Question 1 - Azure AI Services
======================================================================
Question: Which Azure service provides pre-built AI capabilities through REST APIs?

Your answer: B | Correct answer: B

âœ… CORRECT!
ğŸ“– Explanation: Azure Cognitive Services provides pre-built AI capabilities through
    REST APIs, allowing developers to add intelligent features without deep AI expertise.
ğŸ¯ Key concept: Understanding Azure Cognitive Services as pre-built AI APIs

âŒ Question 4 - Machine Learning on Azure
======================================================================
Question: What is the purpose of feature engineering in machine learning?

Your answer: C | Correct answer: A

âŒ INCORRECT
ğŸ“– Why correct answer is right: Feature engineering transforms raw data into meaningful
    features that improve model performance. It's crucial for helping ML models learn patterns.
âš ï¸ Why your answer is wrong: Normalization is one technique used in feature engineering,
    but it's not the primary purpose. Feature engineering is broader and includes creating
    new features from existing data.
ğŸ’¡ Study tip: Review the ML lifecycle and focus on the data preparation phase, particularly
    how feature engineering transforms and creates features to improve model accuracy.
ğŸ¯ Key concept: Feature engineering as data transformation for ML models

... [8 more questions with detailed feedback]

======================================================================
ğŸ’¬ OVERALL FEEDBACK
======================================================================

You demonstrated strong understanding of Azure AI Services with perfect scores. Your
grasp of Machine Learning fundamentals is solid at 75%. However, you should strengthen
your knowledge of Natural Language Processing services like Text Analytics and LUIS,
where you scored 66.7%.

âœ¨ Great job overall! With focused review of NLP concepts, you'll be well-prepared
for the certification exam.

ğŸ¯ NEXT FOCUS AREAS:
  1. Review Azure Text Analytics and Translator service documentation
  2. Complete hands-on labs for NLP workloads, especially sentiment analysis
  3. Practice identifying which Azure AI service fits specific scenarios

======================================================================
PHASE 4: STRATEGIC EXAM READINESS EVALUATION
======================================================================

[AGENT: EXAM_PLAN_AGENT]
Analyzing overall readiness and providing certification recommendation...

ğŸ“‹ EXAM READINESS ASSESSMENT
Certification: AI-900 - Microsoft Azure AI Fundamentals
Level: Fundamentals
Registration: https://learn.microsoft.com/certifications/exams/ai-900

ğŸ“Š READINESS STATUS:
  âš ï¸ Status: NEARLY READY
  ğŸ“ˆ Overall Score: 80%
  ğŸ¯ Confidence: Medium

ğŸ“š DOMAIN PERFORMANCE:
  ğŸŸ¢ Azure AI workloads and considerations
     Weight: 15-20% | Score: 90% | Status: strong

  ğŸŸ¢ Machine learning principles on Azure
     Weight: 30-35% | Score: 85% | Status: strong

  ğŸŸ¡ Computer vision workloads on Azure
     Weight: 15-20% | Score: 65% | Status: adequate

  ğŸŸ¢ Natural Language Processing workloads
     Weight: 25-30% | Score: 80% | Status: strong

ğŸ’¡ RECOMMENDATION:
  âš ï¸ Action: DELAY AND REINFORCE
  ğŸ“ Justification: Your score of 80% is solid, but reinforcing Computer Vision
      (adequate at 65%) will increase confidence before booking.

â±ï¸ PREPARATION TIMELINE:
  â€¢ Days needed: 7
  â€¢ Suggested exam date: 1-2 weeks from now
  â€¢ Rationale: Spend 1 week strengthening Computer Vision concepts (estimated
    8-10 additional study hours) before booking your exam.

ğŸ¯ TARGETED NEXT STEPS:
  1. Focus: Computer Vision workloads on Azure
     Action: Complete hands-on labs for Custom Vision and Form Recognizer services.

ğŸ§  EXAM STRATEGY:
  â€¢ Focus on scenario-based questions involving Computer Vision and NLP
  â€¢ Review Azure AI service pricing models and use case selection
  â€¢ Practice time management: allocate 90 seconds per question

ğŸ“ EXAM DAY TIPS:
  â€¢ Arrive 15 minutes early to the testing center
  â€¢ Read each question carefully and identify key terms
  â€¢ Use the mark-for-review feature for uncertain questions

[SESSION COMPLETED]
```

---

## ğŸ“ Project Structure

```
MS-CertiMentor-Reasoning-Agent/
â”œâ”€â”€ main.py                       # â­ Main entry point
â”œâ”€â”€ test_azure_connection.py     # Connection verification
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ setup.py                      # Package setup
â”œâ”€â”€ LICENSE                       # MIT License
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                   # Agent definitions (6 specialized agents)
â”‚   â”‚   â”œâ”€â”€ agents_factory.py    # Agent creation factory
â”‚   â”‚   â”œâ”€â”€ learning_path_curator.py
â”‚   â”‚   â”œâ”€â”€ study_plan_generator.py
â”‚   â”‚   â”œâ”€â”€ engagement_agent.py
â”‚   â”‚   â”œâ”€â”€ assessment_agent.py
â”‚   â”‚   â”œâ”€â”€ assessment_evaluator_agent.py  # â­ NEW: Educational feedback
â”‚   â”‚   â”œâ”€â”€ exam_plan_agent.py
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ agents_config.py  # Agent configurations
â”‚   â”‚   â””â”€â”€ prompts/              # Agent prompt templates
â”‚   â”‚       â”œâ”€â”€ learning_path_curator.txt
â”‚   â”‚       â”œâ”€â”€ study_plan_generator.txt
â”‚   â”‚       â”œâ”€â”€ engagement_agent.txt
â”‚   â”‚       â”œâ”€â”€ assessment_agent.txt
â”‚   â”‚       â”œâ”€â”€ assessment_evaluator_agent.txt  # â­ NEW
â”‚   â”‚       â””â”€â”€ exam_plan_agent.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                   # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ quiz_models.py       # Quiz structured output
â”‚   â”‚   â”œâ”€â”€ learning_path_models.py  # Learning path data
â”‚   â”‚   â”œâ”€â”€ study_plan_models.py # Study plan data
â”‚   â”‚   â”œâ”€â”€ engagement_models.py # Engagement & reminder data
â”‚   â”‚   â”œâ”€â”€ assessment_evaluator_models.py  # â­ NEW: Feedback models
â”‚   â”‚   â””â”€â”€ exam_plan_models.py  # Exam readiness & certification planning
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                    # Tool functions
â”‚   â”‚   â”œâ”€â”€ microsoft_learn_tools.py  # MCP integration
â”‚   â”‚   â”œâ”€â”€ mcp_client.py        # MCP client implementation
â”‚   â”‚   â”œâ”€â”€ assessment_tools.py
â”‚   â”‚   â”œâ”€â”€ notification_tools.py
â”‚   â”‚   â””â”€â”€ study_plan_tools.py
â”‚   â”‚
â”‚   â”œâ”€â”€ workflows/                # Workflow orchestration
â”‚   â”‚   â”œâ”€â”€ preparation_workflow.py  # Sequential subworkflow
â”‚   â”‚   â”œâ”€â”€ assessment_workflow.py   # Assessment execution
â”‚   â”‚   â””â”€â”€ main_workflow.py     # Complete workflow
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                    # Utilities
â”‚   â”‚   â”œâ”€â”€ state_manager.py
â”‚   â”‚   â””â”€â”€ human_input.py
â”‚   â”‚
â”‚   â””â”€â”€ config.py                 # Configuration management
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/                         # Sample data
â”‚   â””â”€â”€ sample_topics.json
â”‚
â”œâ”€â”€ .agents/                      # External skills
â”‚   â””â”€â”€ skills/
â”‚       â””â”€â”€ microsoft-agent-framework/
â”‚
â””â”€â”€ AZURE_SETUP.md               # Azure setup guide
```

---

## ğŸ¯ Personalization Flow

The system adapts to each student through a comprehensive input collection process:

### User Configuration Inputs

| Input | Values | Impact |
|-------|--------|--------|
| **Certification Topics** | Free text (e.g., "Azure AI Fundamentals") | Determines which Microsoft Learn paths to search |
| **Email** | Email address | Used for reminder notifications (console simulation in MVP) |
| **Experience Level** | `beginner` / `intermediate` / `advanced` | â€¢ Learning Path Curator selects appropriate content difficulty<br>â€¢ Engagement Agent adapts motivational tone<br>â€¢ Assessment questions complexity |
| **Study Days/Week** | 1-7 days | Study Plan Generator creates realistic weekly schedules |
| **Daily Hours** | 0.5-8.0 hours | Determines session length and total plan duration |

### How Each Agent Uses This Information

**Learning Path Curator**
- Filters Microsoft Learn paths by difficulty matching user level
- Beginner â†’ foundational paths, simple explanations
- Intermediate â†’ practical application, real-world scenarios
- Advanced â†’ deep-dive content, optimization techniques

**Study Plan Generator**
- Calculates total weekly capacity: `days Ã— hours = weekly hours`
- Distributes learning modules across available days
- Adjusts plan duration to match realistic completion timeline
- Example: 5 days/week Ã— 2 hours/day = 10 hours/week â†’ 6-week plan for 60-hour curriculum

**Engagement Agent**
- **Beginner tone**: Supportive, confidence-building, celebrates small wins
- **Intermediate tone**: Challenge-oriented, practical application focus
- **Advanced tone**: Performance-focused, mastery emphasis
- Reminder frequency matches study schedule (5 days/week â†’ no weekend reminders)

### Example Configurations

**Configuration 1: Busy Professional**
```
Level: intermediate
Days: 3 days/week
Hours: 1.5 hours/day
â†’ Result: 9-week extended plan, practical focus, flexible pacing
```

**Configuration 2: Full-time Student**
```
Level: beginner
Days: 6 days/week
Hours: 4 hours/day
â†’ Result: 3-week intensive plan, supportive tone, fast-track
```

**Configuration 3: Weekend Learner**
```
Level: advanced
Days: 2 days/week (weekends)
Hours: 5 hours/day
â†’ Result: 6-week plan, deep-dive content, concentrated sessions
```

---

## ğŸ“ˆ Exam Readiness Assessment System

The Exam Plan Agent uses a sophisticated multi-criteria decision system to determine student readiness.

### Intelligent Quiz Evaluation Process

Unlike traditional systems with fixed pass/fail thresholds, **the Exam Plan Agent evaluates the complete quiz** using AI-powered analysis:

**What the agent receives:**
- Complete quiz with 10 questions (domains, difficulty, Bloom levels)
- Student's answers for all questions
- Correct answers for validation

**What the agent calculates:**
1. **Overall Score**: Percentage of correct answers
2. **Domain-Level Scores**: Performance grouped by exam domain
3. **Domain Status**: Classifies each domain as strong/adequate/weak
4. **Critical Risks**: Identifies high-weight domains with low scores
5. **Readiness Status**: Applies decision logic (ready/nearly_ready/not_ready)
6. **Preparation Timeline**: Estimates days needed based on weak domains

**Key Benefits:**
- âœ… **No fixed pass/fail** - provides feedback at any score level
- âœ… **Domain-aware** - identifies specific weak areas
- âœ… **Personalized** - recommendations tailored to performance pattern
- âœ… **Actionable** - specific next steps for improvement
- âœ… **Intelligent** - considers exam weights and question difficulty

### Decision Thresholds

| Overall Score | Status | Recommended Action | Timeline |
|---------------|--------|-------------------|----------|
| **â‰¥80%** + No critical risks | âœ… Ready | Book exam immediately | Within 1 week |
| **65-79%** | âš ï¸ Nearly Ready | Delay and reinforce weak areas | 1-2 weeks |
| **<65%** | âŒ Not Ready | Rebuild foundation | 3-4+ weeks |

### Critical Risk Detection

A **critical risk** is identified when:
- A domain with **exam weight >20%** scores **<60%**
- Example: Machine Learning (30-35% weight) scoring 45% â†’ Critical weakness

### Domain Status Classification

| Score Range | Status | Icon | Meaning |
|-------------|--------|------|---------|
| **â‰¥70%** | Strong | ğŸŸ¢ | Well-prepared in this domain |
| **60-69%** | Adequate | ğŸŸ¡ | Meets minimum but needs reinforcement |
| **<60%** | Weak | ğŸ”´ | Requires significant additional study |

### Preparation Timeline Calculation

**Formula**: `(number of weak domains Ã— 5-10 hours per domain) Ã· daily study hours`

**Examples:**
```
Scenario 1: Ready Now
- Overall: 85%, All domains: strong
- Days needed: null (0 days)
- Suggested date: "within 1 week"

Scenario 2: Nearly Ready
- Overall: 72%, 1 adequate domain, 1 weak domain
- Days needed: 10 days
- Suggested date: "1-2 weeks from now"

Scenario 3: Not Ready
- Overall: 58%, 2 weak domains (high-weight)
- Days needed: 21 days
- Suggested date: "3-4 weeks from now"
```

### Confidence Level

| Confidence | When Applied |
|------------|-------------|
| **High** | Score â‰¥80%, consistent performance across all domains |
| **Medium** | Score 60-79%, some variation in domain performance |
| **Low** | Score <60%, significant domain weaknesses |

---

## ğŸ”„ Reasoning Patterns

| Pattern | Implementation | Purpose |
|---------|---------------|---------|
| **Planner-Executor** | Curator plans â†’ Others execute | Clear role separation |
| **Sequential Orchestration** | `SequentialBuilder` | Structured agent pipeline |
| **Iterative Refinement** | Assessment loop (max 3) | Learning from failure |
| **Role-Based Specialization** | 6 distinct agents | Reduce overlap, increase quality |
| **Human-in-the-Loop** | Checkpoint before assessment | Safety & control |
| **Educational Feedback Loop** | Assessment Evaluator explains answers | Immediate learning from mistakes |
| **Separation of Concerns** | Evaluator (learning) vs Exam Planner (strategy) | Educational vs strategic assessment |
| **Intelligent Evaluator** | Exam Plan Agent analyzes quiz holistically | AI-powered assessment, not fixed rules |
| **Context-Aware Decision Making** | Agents receive full quiz context | Domain-aware, personalized recommendations |

---

## ğŸ“ Key Features

### âœ… Implemented

- [x] Multi-agent orchestration with Sequential Workflows
- [x] Azure OpenAI Service integration
- [x] **6 specialized agents** with custom temperatures (NEW: Assessment Evaluator)
- [x] Structured outputs using Pydantic models (Quiz, AssessmentFeedback, CuratedLearningPlan, StudyPlan, EngagementPlan, ExamPlan)
- [x] Microsoft Learn MCP integration
- [x] Interactive certification-style assessments
- [x] Human approval checkpoints
- [x] **Question-by-question educational feedback** (NEW: explains correct/incorrect answers)
- [x] **Detailed learning explanations** (NEW: why correct is right, why wrong is wrong)
- [x] **Specific study tips** (NEW: actionable guidance for each mistake)
- [x] **Key concept identification** (NEW: highlights what each question tests)
- [x] **Encouraging constructive tone** (NEW: motivational feedback regardless of score)
- [x] **AI-powered quiz evaluation** (no fixed pass/fail thresholds)
- [x] **Intelligent feedback loop** (always provides guidance, regardless of score)
- [x] **Level-aware learning path curation** (beginner/intermediate/advanced)
- [x] **Availability-based study planning** (customizable days/week and hours/day)
- [x] **Adaptive engagement tone** based on student experience level
- [x] Automated reminder scheduling with direct resource URLs
- [x] **Domain-level performance breakdown** with exam weights and status indicators
- [x] **Intelligent readiness assessment** with decision thresholds (ready/nearly_ready/not_ready)
- [x] **Automatic score calculation** by domain and overall
- [x] **Preparation timeline calculator** with realistic date suggestions
- [x] **Critical risk detection** for high-weight weak domains
- [x] **Personalized recommendations** based on question-level performance
- [x] Milestone tracking with validation checkpoints
- [x] Buffer/rest session management
- [x] **Azure Application Insights observability** (spans, traces, custom attributes)

### ğŸ”® Future Enhancements

- [ ] Email/SMS notifications via Azure Communication Services
- [ ] Persistent state with Azure Cosmos DB
- [ ] Telemetry with Application Insights
- [ ] Web UI with React + FastAPI
- [ ] Multi-language support
- [ ] Advanced progress tracking dashboard

---

## ğŸ“Š Structured Data Models

The system uses Pydantic v2 models for structured outputs from agents:

### CuratedLearningPlan (Learning Path Curator)
```python
{
  "exam": "AI-900",
  "user_level": "beginner",
  "priority_domains": [
    {
      "domain_name": "Azure AI Services",
      "exam_weight": "30-35%",
      "priority_level": "High",
      "reason": "Core exam topic with highest weight"
    }
  ],
  "recommended_learning_paths": [
    {
      "title": "Azure AI Fundamentals",
      "url": "https://learn.microsoft.com/...",
      "estimated_hours": "8h",
      "relevance_score": 10,
      "modules": [...]
    }
  ]
}
```

### StudyPlan (Study Plan Generator)
```python
{
  "plan_title": "AI-900 Certification Study Plan",
  "total_duration_weeks": 6,
  "daily_hours_target": 2.0,
  "study_days_per_week": 5,
  "weeks": [
    {
      "week_number": 1,
      "week_theme": "Azure AI Fundamentals",
      "total_hours": 10.0,
      "sessions": [
        {
          "day_number": 1,
          "day_of_week": "Monday",
          "session_type": "learning",
          "topic": "Introduction to AI",
          "estimated_hours": 2.0,
          "resources": ["https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/"]
        }
      ]
    }
  ],
  "milestones": [
    {"percentage": 25, "week_number": 2, "description": "..."},
    {"percentage": 50, "week_number": 3, "description": "..."},
    {"percentage": 75, "week_number": 5, "description": "..."},
    {"percentage": 100, "week_number": 6, "description": "..."}
  ]
}
```

### EngagementPlan (Engagement Agent)
```python
{
  "certification_goal": "AI-900",
  "user_level": "beginner",
  "total_reminders": 33,
  "study_duration_weeks": 6,
  "reminders": [
    {
      "date_time": "Day 1 (Monday)",
      "study_item": "Introduction to AI",
      "reminder_type": "session",
      "reminder": "Great start! Today you'll explore AI basics and Azure AI services.",
      "link": "https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/"
    },
    {
      "date_time": "Week 2",
      "study_item": "25% Milestone",
      "reminder_type": "milestone",
      "reminder": "Congratulations! You've completed 25% of your study plan.",
      "link": null
    }
  ],
  "motivation_strategy": "Beginner-supportive approach with confidence building and celebration of small wins",
  "accountability_tips": [
    "Set a specific study time each day and treat it like an appointment",
    "Track your progress visually with a checklist or calendar",
    "Join a study group or find an accountability partner"
  ]
}
```

### Quiz (Assessment Agent)

Generated by the Assessment Agent for student evaluation. The quiz contains domain-mapped questions that are later evaluated by the Exam Plan Agent.

```python
{
  "total_questions": 10,
  "difficulty_distribution": {"easy": 3, "medium": 5, "hard": 2},
  "questions": [
    {
      "question_number": 1,
      "question_text": "Which Azure service is best for ML workloads?",
      "domain": "Azure AI Services",  # Maps to exam domain
      "options": ["A", "B", "C", "D"],
      "correct_answer": "B",
      "difficulty": "medium",
      "bloom_level": "apply",
      "is_scenario_based": true,
      "explanation": "Azure Machine Learning provides...",
      "microsoft_learn_reference": "https://learn.microsoft.com/..."
    }
  ]
}
```

**Note**: The Assessment Agent generates the quiz but does NOT evaluate answers. Student responses are collected and sent to both the Assessment Evaluator (for educational feedback) and Exam Plan Agent (for strategic readiness evaluation).

### AssessmentFeedback (Assessment Evaluator Agent) â­ NEW
```python
{
  "total_questions": 10,
  "correct_count": 7,
  "incorrect_count": 3,
  "score_percentage": 70.0,
  "passed": true,
  "questions_feedback": [
    {
      "question_number": 1,
      "domain": "Azure AI Services",
      "question_text": "What is Azure Cognitive Services?",
      "student_answer": "B",
      "correct_answer": "B",
      "is_correct": true,
      "correct_explanation": "Azure Cognitive Services is a set of pre-built AI APIs that enable developers to add intelligent features to applications without deep AI expertise...",
      "incorrect_explanation": null,
      "key_concept": "Understanding Azure Cognitive Services as pre-built AI APIs",
      "study_tip": null
    },
    {
      "question_number": 2,
      "domain": "Machine Learning",
      "question_text": "What is supervised learning?",
      "student_answer": "C",
      "correct_answer": "A",
      "is_correct": false,
      "correct_explanation": "Supervised learning is a machine learning approach where the model is trained on labeled data...",
      "incorrect_explanation": "Your answer describes unsupervised learning. Supervised learning requires labeled training data with known correct answers.",
      "key_concept": "Distinction between supervised and unsupervised learning",
      "study_tip": "Review the key difference: supervised uses labeled data, unsupervised finds patterns in unlabeled data."
    }
  ],
  "domain_performance": [
    {
      "domain_name": "Azure AI Services",
      "total_questions": 3,
      "correct_answers": 2,
      "score_percentage": 66.7,
      "status": "adequate"
    },
    {
      "domain_name": "Machine Learning on Azure",
      "total_questions": 4,
      "correct_answers": 3,
      "score_percentage": 75.0,
      "status": "strong"
    }
  ],
  "strengths": [
    "Machine Learning on Azure (75% - strong grasp of ML fundamentals)",
    "Applied scenario questions (3/4 correct)"
  ],
  "weaknesses": [
    "Azure AI Services (66.7% - need to review Cognitive Services APIs)",
    "Natural Language Processing (66.7% - concepts need reinforcement)"
  ],
  "overall_feedback": "You demonstrated solid understanding of Machine Learning fundamentals with 75% accuracy. Your ability to analyze scenario-based questions is a strength. Focus on strengthening Azure AI Services and NLP concepts.",
  "motivational_message": "Great job on ML concepts! With focused review of Azure AI services, you'll be well-prepared for the exam.",
  "next_focus_areas": [
    "Review Azure Cognitive Services documentation, focusing on Computer Vision and Text Analytics APIs",
    "Complete hands-on labs for NLP workloads",
    "Practice scenario questions requiring service selection"
  ]
}
```

**Key Features:**
- **Question-by-Question Feedback**: Detailed explanation for each answer (correct and incorrect)
- **Educational Explanations**: "Why correct is right" + "Why wrong is wrong" for mistakes
- **Study Tips**: Specific, actionable guidance for each incorrect answer
- **Key Concepts**: Highlights the learning objective being tested
- **Domain Performance**: Groups results by certification domain
- **Strengths & Weaknesses**: Clear identification of strong/weak areas
- **Encouraging Tone**: Constructive, motivational feedback regardless of score
- **Actionable Next Steps**: Prioritized focus areas based on performance

### ExamPlan (Exam Plan Agent)
```python
{
  "exam": {
    "code": "AI-900",
    "name": "Microsoft Azure AI Fundamentals",
    "level": "fundamentals",
    "registration_url": "https://learn.microsoft.com/certifications/exams/ai-900"
  },
  "readiness_assessment": {
    "overall_score": 85,
    "status": "ready",
    "confidence_level": "high",
    "critical_risks": [],
    "domain_breakdown": [
      {
        "domain_name": "Describe AI workloads and considerations",
        "exam_weight": "15-20%",
        "score": 90,
        "status": "strong"
      },
      {
        "domain_name": "Describe fundamental principles of machine learning on Azure",
        "exam_weight": "30-35%",
        "score": 85,
        "status": "strong"
      },
      {
        "domain_name": "Describe features of computer vision workloads on Azure",
        "exam_weight": "15-20%",
        "score": 75,
        "status": "strong"
      },
      {
        "domain_name": "Describe features of NLP workloads on Azure",
        "exam_weight": "25-30%",
        "score": 88,
        "status": "strong"
      }
    ]
  },
  "recommendation": {
    "action": "book_exam",
    "justification": "Your overall score of 85% exceeds the readiness threshold with strong performance across all high-weight domains."
  },
  "preparation_timeline": {
    "days_needed": null,
    "suggested_exam_date_range": "within 1 week",
    "rationale": "You are ready to book your exam now. All domains show strong performance with no critical gaps."
  },
  "targeted_next_steps": [
    {
      "focus_domain": "Computer Vision workloads",
      "recommended_action": "Review Custom Vision API documentation to boost confidence in this area."
    }
  ],
  "exam_strategy": [
    "Focus on scenario-based questions involving Computer Vision and NLP",
    "Review Azure AI service pricing models and use case selection",
    "Practice time management: allocate 90 seconds per question on average"
  ],
  "exam_day_tips": [
    "Arrive 15 minutes early to the testing center",
    "Read each question carefully and identify key terms",
    "Use the mark-for-review feature for uncertain questions"
  ]
}
```

**Key Features:**
- **Domain Performance Breakdown**: Transparent score breakdown by exam domain with weights and status (strong/adequate/weak)
- **Preparation Timeline**: Realistic timeline with days needed, suggested exam dates, and clear rationale
- **Decision Thresholds**: â‰¥80% â†’ ready to book, 65-79% â†’ delay and reinforce, <65% â†’ rebuild foundation
- **Critical Risk Detection**: Identifies high-weight domains (>20%) scoring <60%
- **Actionable Next Steps**: Domain-specific preparation actions prioritized by weakness

---

## ğŸ”§ MCP Integration

The system integrates with Microsoft Learn via the Model Context Protocol (MCP):

**Endpoints Used:**
- `search_learning_paths` - Search for relevant learning paths
- `get_module_details` - Fetch detailed module information
- `search_certifications` - Find certification exams

**MCP Client:** `src/tools/mcp_client.py`
- JSON-RPC 2.0 over HTTP
- Server-Sent Events (SSE) support
- Automatic retry with exponential backoff
- Error handling and fallback mechanisms

**Resource URL Flow:**
```
Microsoft Learn MCP
        â†“
Learning Path Curator (extracts module URLs)
        â†“
Study Plan Generator (includes URLs in DailySession.resources)
        â†“
Engagement Agent (uses URLs in session reminders)
```

This ensures every learning session reminder links directly to the correct Microsoft Learn module.

---

## ğŸ“Š Evaluation Criteria (AgentsLeague)

| Criterion | Weight | Implementation |
|-----------|--------|---------------|
| **Accuracy & Relevance** | 25% | Relevant paths, proper exam recommendations, accurate feedback |
| **Reasoning & Multi-step Thinking** | 25% | 6 specialized agents, sequential workflow, educational feedback loop, strategic assessment |
| **Reliability & Safety** | 20% | Iteration limits, human checkpoints, constructive feedback, observability |
| **User Experience** | 15% | Polished CLI, clear output, interactive quiz, detailed explanations, encouraging tone |
| **Creativity** | 15% | Dual-layer evaluation (educational + strategic), temperature tuning, adaptive engagement |

---

## ğŸ›¡ï¸ Responsible AI

- âœ… Human approval required before assessment
- âœ… Maximum 3 assessment attempts (prevents infinite loops)
- âœ… Objective 70% passing threshold
- âœ… **Detailed educational feedback** - explains correct/incorrect answers to promote learning
- âœ… **Encouraging tone** - constructive feedback that motivates, not discourages
- âœ… **Separation of learning and evaluation** - Educational feedback before strategic assessment
- âœ… Constructive guidance regardless of score (no "game over")
- âœ… Educational focus only (no exam dumps, teaches concepts)
- âœ… Privacy-conscious (console-only notifications in MVP)
- âœ… Observability with Azure Application Insights (opt-in)

---

## ğŸ“Š Observability

The system includes comprehensive observability with Azure Application Insights:

- **Workflow Phases**: All major phases traced (preparation, assessment, evaluation, exam planning)
- **Agent Executions**: Each agent run captured with duration and tokens
- **Custom Spans**: Fine-grained tracing (quiz generation, evaluation, user input)
- **Custom Attributes**: 40+ attributes including student data, scores, domain performance
- **Azure OpenAI Calls**: Automatic instrumentation of API calls
- **GenAI Semantic Conventions**: Follows OpenTelemetry standards

**Setup:**
1. Add `APPLICATION_INSIGHTS_CONNECTION_STRING` to `.env`
2. Set `ENABLE_OBSERVABILITY=true`
3. Run workflow - traces automatically sent to Azure Portal

**View Traces:**
- Azure Portal â†’ Application Insights â†’ Transaction Search
- Use Kusto queries in Logs blade for analysis

See **[OBSERVABILITY.md](OBSERVABILITY.md)** for complete documentation, setup guide, and example queries.

---

## ğŸ§ª Testing

### Test Connection

```bash
python test_azure_connection.py
```

### Run Test Suite

```bash
pytest tests/ -v
```

---

## ğŸ› Troubleshooting

### "Cannot connect to host"
- Verify `AZURE_OPENAI_ENDPOINT` is correct
- Check firewall/network settings
- Ensure Azure OpenAI resource is active

### "API key invalid"
- Regenerate key in Azure Portal
- Copy KEY 1 (not KEY 2)
- Remove any extra spaces from `.env` file

### "Deployment not found"
- Verify deployment name in Azure Portal â†’ Model deployments
- Ensure model is deployed (not just available)

### "Module not found"
- Run `pip install -r requirements.txt`
- Ensure Python 3.9+ is installed
- Consider using a virtual environment

---

## ğŸ™ Acknowledgments

- **Microsoft Agent Framework** - Agent orchestration framework
- **Azure OpenAI Service** - LLM inference
- **Microsoft Learn** - Certification content and MCP server
- **AgentsLeague** - Challenge platform and community

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details.

This project is developed for the AgentsLeague Battle #2 challenge.

---

**Status**: âœ… Fully Functional | **Track**: Reasoning Agents | **Platform**: Microsoft Agent Framework

**Demo Video**: [Coming soon]

**Date**: February 2026
**Challenge**: AgentsLeague Battle #2 - Reasoning Agents with Microsoft Foundry
